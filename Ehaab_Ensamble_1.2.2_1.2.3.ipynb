{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoImageProcessor, ResNetForImageClassification, ResNetConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Task Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download & process dataset\n",
    "dataset = load_dataset(\"Maysee/tiny-imagenet\")\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"preprocessor_config.json\",)\n",
    "\n",
    "def process_example(example):\n",
    "    if example['image'].mode != 'RGB':\n",
    "        example['image'] = example['image'].convert('RGB')\n",
    "    example = processor(example['image'], return_tensors='pt')\n",
    "    example['pixel_values'] = example['pixel_values'].squeeze()\n",
    "    return example\n",
    "\n",
    "dataset['valid'] = dataset['valid'].map(process_example)\n",
    "dataset['valid'].set_format(\"pt\", columns=['pixel_values'], output_all_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {\n",
    "    1: [182, 61, 120, 193, 12, 23, 146, 165, 142, 171, 9, 45, 50, 192, 123, 156, 31, 89, 100, 65, 5, 75,\n",
    "        157, 158, 139, 154, 35, 67, 58, 105, 29, 17, 150, 122, 15, 62, 167, 174, 60, 110, 133, 145, 199],\n",
    "    2: [114, 169, 40, 18, 19, 49, 187, 83, 16, 34, 47, 59, 166, 68, 32, 197, 52, 3, 51, 190, 66, 94, 170,\n",
    "        196, 116, 138, 184, 181, 137, 128, 14, 55, 140, 76, 135, 121, 88, 124, 85, 130, 43, 162, 24, 180,\n",
    "        20, 63, 155, 107, 96, 134, 175, 69, 82, 109, 56, 115, 136, 70, 80, 41],\n",
    "    3: [10, 92, 103, 86, 189, 64, 179, 147, 13, 53, 198, 1, 72, 48, 77, 36, 42, 73],\n",
    "    4: [39, 195, 126, 191, 99, 144, 160, 104, 159, 21, 161, 6, 176, 113, 168, 102, 194, 148, 30, 119,\n",
    "        87, 27, 106, 2, 143, 74, 79, 132, 178, 101, 28, 186, 97, 111, 91, 117, 127, 22, 71, 118, 44, 177,\n",
    "        153, 172],\n",
    "    5: [81, 151, 0, 37, 33, 11, 141, 112, 183, 149, 7, 173, 125, 108, 185, 25, 129, 163, 84, 54, 26, 152,\n",
    "        78, 38, 188, 4, 95, 98, 57, 131, 90, 46, 8, 164, 93]\n",
    "}\n",
    "# Create dataset for each task\n",
    "train_datasets = {}\n",
    "val_datasets = {}\n",
    "for t in tasks.keys():\n",
    "    split = dataset['train'].filter(lambda img: img['label'] in tasks[t]).train_test_split(test_size=0.2)\n",
    "    train_datasets[t] = split['train']\n",
    "    val_datasets[t] = split['test']\n",
    "    val_datasets[t] = val_datasets[t].map(process_example)\n",
    "    val_datasets[t].set_format(\"pt\", columns=['pixel_values'], output_all_columns=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train baseline models\n",
    "config = ResNetConfig(num_labels=200, num_channels=3)\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "models = {}\n",
    "\n",
    "for t in tasks.keys():\n",
    "    models[t] = ResNetForImageClassification(config)\n",
    "    training_args = TrainingArguments(output_dir=f\"./task_{t}\", evaluation_strategy=\"epoch\", num_train_epochs=50,)\n",
    "    train_data = train_datasets[t].map(process_example)\n",
    "    train_data.set_format(\"pt\", columns=['pixel_values'], output_all_columns=True)\n",
    "    trainer = Trainer(\n",
    "        model=models[t],\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=dataset['valid'],\n",
    "    )\n",
    "    trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 model\tAccuracy: 0.15%\n",
      "Task 2 model\tAccuracy: 0.20%\n",
      "Task 3 model\tAccuracy: 0.07%\n",
      "Task 4 model\tAccuracy: 0.15%\n",
      "Task 5 model\tAccuracy: 0.12%\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline models on combined validation dataset\n",
    "for t in tasks.keys():\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for example in dataset['valid']:\n",
    "            predicted_label = models[t](example['pixel_values'].unsqueeze(0).cuda()).logits.argmax(-1).item()\n",
    "            predictions.append(predicted_label)\n",
    "    acc = accuracy_score(dataset['valid']['label'], predictions)\n",
    "    print('Task {} model\\tAccuracy: {:.2f}%'.format(t,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate baseline models on tasks only validation dataset\n",
    "for t in tasks.keys():\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for example in val_datasets[t]:\n",
    "            predicted_label = models[t](example['pixel_values'].unsqueeze(0).cuda()).logits.argmax(-1).item()\n",
    "            predictions.append(predicted_label)\n",
    "    acc = accuracy_score(val_datasets[t]['label'], predictions)\n",
    "    print('Task {}\\tAccuracy: {:.2f}%'.format(t,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "models = {}\n",
    "for t in tasks.keys():\n",
    "    models[t] = ResNetForImageClassification.from_pretrained(f'task_{t}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection and Aggregation Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1409\n"
     ]
    }
   ],
   "source": [
    "# random selection\n",
    "random.seed(2)\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for example in dataset['valid']:\n",
    "        m = random.choice(list(models.keys()))\n",
    "        predicted_label = models[m](example['pixel_values'].unsqueeze(0).cuda()).logits.argmax(-1).item()\n",
    "        predictions.append(predicted_label)\n",
    "acc = accuracy_score(dataset['valid']['label'], predictions)\n",
    "print('Accuracy: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69%\n"
     ]
    }
   ],
   "source": [
    "# Oracle Selection\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for example in dataset['valid']:\n",
    "        m = None\n",
    "        for t in tasks.keys():\n",
    "            if example['label'] in tasks[t]:\n",
    "                m = t\n",
    "                break\n",
    "        predicted_label = models[m](example['pixel_values'].unsqueeze(0).cuda()).logits.argmax(-1).item()\n",
    "        predictions.append(predicted_label)\n",
    "acc = accuracy_score(dataset['valid']['label'], predictions)\n",
    "print('Accuracy: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4248\n"
     ]
    }
   ],
   "source": [
    "# Confidence-based Selection\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for example in dataset['valid']:\n",
    "        candidates = {}\n",
    "        for t in tasks.keys():\n",
    "            logits =  models[t](example['pixel_values'].unsqueeze(0).cuda()).logits\n",
    "            predicted_label = logits.argmax(-1).item()\n",
    "            pred_confidence = logits.max().item()\n",
    "            candidates[predicted_label] = pred_confidence\n",
    "        predicted_label = max(candidates, key=candidates.get)\n",
    "        predictions.append(predicted_label)\n",
    "acc = accuracy_score(dataset['valid']['label'], predictions)\n",
    "print('Accuracy: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4364\n"
     ]
    }
   ],
   "source": [
    "# Entropy-based Selection\n",
    "def entropy(logits):\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    log_probs = torch.log(probs + 1e-7) # Add a small epsilon to avoid log(0)\n",
    "    entropy = -torch.sum(probs * log_probs, dim=1)\n",
    "    return entropy.item()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for example in dataset['valid']:\n",
    "        candidates = {}\n",
    "        for t in tasks.keys():\n",
    "            logits =  models[t](example['pixel_values'].unsqueeze(0).cuda()).logits\n",
    "            predicted_label = logits.argmax(-1).item()\n",
    "            entr = entropy(logits)\n",
    "            candidates[predicted_label] = entr\n",
    "        predicted_label = min(candidates, key=candidates.get)\n",
    "        predictions.append(predicted_label)\n",
    "acc = accuracy_score(dataset['valid']['label'], predictions)\n",
    "print('Accuracy: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking\n",
    "# Define Stacked model\n",
    "class StackingEnsemble(nn.Module):\n",
    "    def __init__(self, models, num_classes=200, hidden_size=512):\n",
    "        super(StackingEnsemble, self).__init__()\n",
    "        self.models = nn.ModuleList(models)\n",
    "        self.num_classes = num_classes\n",
    "        self.pooler = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(len(models) * hidden_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values: torch.FloatTensor = None,):\n",
    "        # Pass input through the ensemble\n",
    "        outputs = []\n",
    "        for model in self.models:\n",
    "            last_hidden_state = model(pixel_values, return_dict=True, output_hidden_states=True)[\n",
    "                'hidden_states'][-1]\n",
    "            pooled_output = self.pooler(last_hidden_state)\n",
    "            outputs.append(pooled_output)\n",
    "\n",
    "        # Stack the penultimate layer feature representations\n",
    "        stacked_features = torch.cat(outputs, dim=1)\n",
    "        stacked_features = stacked_features.view(stacked_features.size(0), -1)\n",
    "\n",
    "        # Pass stacked features through the classification head\n",
    "        logits = self.classifier(stacked_features)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset \n",
    "# Train baseline models on 80% of train data\n",
    "config = ResNetConfig.from_json_file('task_1\\config.json')\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "models = {}\n",
    "# Keep 20% of each task to finetune Stacked model\n",
    "finetune_data = []\n",
    "for t in tasks.keys():\n",
    "    models[t] = ResNetForImageClassification(config)\n",
    "    training_args = TrainingArguments(output_dir=f\"./resnet_task_80%_{t}\", num_train_epochs=10,\n",
    "                                      save_total_limit=1, overwrite_output_dir=True, auto_find_batch_size=True, save_strategy='epoch')\n",
    "    split = train_datasets[t].map(\n",
    "        process_example).train_test_split(test_size=0.2)\n",
    "    finetune_data.append(split['test'])\n",
    "    split['train'].set_format(\n",
    "        \"pt\", columns=['pixel_values'], output_all_columns=True)\n",
    "    trainer = Trainer(\n",
    "        model=models[t],\n",
    "        args=training_args,\n",
    "        train_dataset=split['train'],\n",
    "    )\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [27:33<00:00, 10.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [27:22<00:00, 10.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [28:03<00:00, 10.72s/it]\n"
     ]
    }
   ],
   "source": [
    "# Train Stacked model\n",
    "stacking_ensemble = StackingEnsemble(list(models.values()))\n",
    "stacked_dataset = concatenate_datasets(finetune_data).with_format(\"torch\")\n",
    "train_dataloader = torch.utils.data.DataLoader(stacked_dataset, batch_size=128)\n",
    "num_epochs = 3\n",
    "# Freeze all other params to train only the last classification layer\n",
    "for name, param in stacking_ensemble.named_parameters():\n",
    "    if name not in ['classifier.1.weight', 'classifier.1.bias']:\n",
    "        param.requires_grad = False\n",
    "optimizer = optim.Adam(stacking_ensemble.parameters(), lr=0.001) \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "for epoch in range(num_epochs):\n",
    "    print(f'EPOCH: {epoch}')\n",
    "    for ex in train_dataloader:\n",
    "        logits = stacking_ensemble(ex['pixel_values'])\n",
    "        loss = criterion(logits, ex['label'])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the StackingEnsemble model on the combined validation set\n",
    "# Define validation dataloader\n",
    "val_dataset = dataset['valid'].with_format(\"torch\")\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=128)\n",
    "\n",
    "device = 'cuda'\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "stacking_ensemble.eval()\n",
    "stacking_ensemble.to(device)\n",
    "with torch.no_grad():\n",
    "    # Loop through the data loader\n",
    "    for ex in  val_dataloader:\n",
    "        # Move images and labels to device\n",
    "        images = ex['pixel_values'].to(device)\n",
    "        labels = ex['label'].to(device)\n",
    "\n",
    "        # Forward pass to get model predictions\n",
    "        outputs = stacking_ensemble(images)\n",
    "\n",
    "        # Get the predicted labels as the index of the maximum output value\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Update total samples\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Update correct predictions\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (correct / total) * 100\n",
    "\n",
    "print('Accuracy: {:.2f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': stacking_ensemble.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss}, 'stacking_ensemble.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
